{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airbnb Data Preparation and Cleaning Workshop\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. Data Collection & Integration\n",
    "print(\"1. Data Collection & Integration\")\n",
    "\n",
    "# Exercise 1: Load the Airbnb datasets\n",
    "# Your task: Load the three Airbnb datasets: contacts.csv, listings.csv, and users.csv\n",
    "# Hint: Use pd.read_csv() for each file\n",
    "\n",
    "# Your code here:\n",
    "contacts = \n",
    "listings = \n",
    "users = \n",
    "\n",
    "print(\"Shapes of loaded datasets:\")\n",
    "print(f\"Contacts: {contacts.shape}\")\n",
    "print(f\"Listings: {listings.shape}\")\n",
    "print(f\"Users: {users.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Inspection\n",
    "print(\"\\n2. Data Inspection\")\n",
    "\n",
    "# Exercise 2: Explore each dataset\n",
    "# Your tasks: \n",
    "# For each dataset (contacts, listings, users):\n",
    "# a) Display basic information about the dataset\n",
    "# b) Show the first few rows\n",
    "# c) Calculate and display summary statistics for numerical columns\n",
    "# d) Check for missing values\n",
    "\n",
    "# Your code here for contacts:\n",
    "# a)\n",
    "# b)\n",
    "# c)\n",
    "# d)\n",
    "\n",
    "# Your code here for listings:\n",
    "# a)\n",
    "# b)\n",
    "# c)\n",
    "# d)\n",
    "\n",
    "# Your code here for users:\n",
    "# a)\n",
    "# b)\n",
    "# c)\n",
    "# d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Handling Missing Values\n",
    "print(\"\\n3. Handling Missing Values\")\n",
    "\n",
    "# Exercise 3: Identify and handle missing values in each dataset\n",
    "# Your tasks:\n",
    "# a) Calculate the percentage of missing values for each column in each dataset\n",
    "# b) Decide on a strategy for handling missing values (e.g., imputation, deletion)\n",
    "# c) Implement your chosen strategy\n",
    "\n",
    "# Your code here for contacts:\n",
    "\n",
    "# Your code here for listings:\n",
    "\n",
    "# Your code here for users:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Removing Duplicates\n",
    "print(\"\\n4. Removing Duplicates\")\n",
    "\n",
    "# Exercise 4: Check for and remove any duplicate rows in each dataset\n",
    "# Hint: Use .duplicated() and .drop_duplicates()\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Handling Outliers\n",
    "print(\"\\n5. Handling Outliers\")\n",
    "\n",
    "# Exercise 5: Identify and handle outliers in numerical columns\n",
    "# Your tasks:\n",
    "# a) Use visualization (e.g., boxplots) to identify potential outliers in numerical columns\n",
    "# b) Implement a method to handle these outliers (e.g., capping, removal)\n",
    "# Hint: Focus on columns like 'price' in the listings dataset\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Data Type Conversion\n",
    "print(\"\\n6. Data Type Conversion\")\n",
    "\n",
    "# Exercise 6: Convert data types as needed\n",
    "# Your tasks:\n",
    "# a) Identify columns that need type conversion (e.g., strings to datetime, objects to category)\n",
    "# b) Perform the necessary type conversions\n",
    "# Hint: Use .astype() or pd.to_datetime()\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Handling Inconsistent Data\n",
    "print(\"\\n7. Handling Inconsistent Data\")\n",
    "\n",
    "# Exercise 7: Identify and correct inconsistencies in the data\n",
    "# Your task: Look for and resolve any inconsistencies across the datasets\n",
    "# (e.g., different formats for the same information, inconsistent category names)\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature Scaling\n",
    "print(\"\\n8. Feature Scaling\")\n",
    "\n",
    "# Exercise 8: Scale numerical features in the listings dataset\n",
    "# Your tasks:\n",
    "# a) Identify numerical features that should be scaled\n",
    "# b) Apply StandardScaler to these features\n",
    "# Hint: Consider columns like 'price', 'number_of_reviews', etc.\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Encoding Categorical Variables\n",
    "print(\"\\n9. Encoding Categorical Variables\")\n",
    "\n",
    "# Exercise 9: Encode categorical variables\n",
    "# Your tasks:\n",
    "# a) Identify categorical variables that need encoding (e.g., 'room_type' in listings)\n",
    "# b) Apply one-hot encoding to these variables\n",
    "# Hint: Use pd.get_dummies() or OneHotEncoder from sklearn\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Data Validation\n",
    "print(\"\\n10. Data Validation\")\n",
    "\n",
    "# Discussion: How would you validate the cleaned and prepared data?\n",
    "# Consider the following questions:\n",
    "# 1. What types of checks would you implement to ensure data integrity?\n",
    "# 2. How would you verify that your data cleaning steps were successful?\n",
    "# 3. What domain-specific validations might be relevant for Airbnb data?\n",
    "\n",
    "# Write your thoughts here:\n",
    "\"\"\"\n",
    "Your data validation thoughts here\n",
    "\"\"\"\n",
    "\n",
    "# 11. Data Storage\n",
    "print(\"\\n11. Data Storage\")\n",
    "\n",
    "# Discussion: How would you approach storing the cleaned and prepared data?\n",
    "# Consider the following questions:\n",
    "# 1. What file format would you choose for storing the prepared data? Why?\n",
    "# 2. How would you structure the data for efficient retrieval and analysis?\n",
    "# 3. What considerations should be made for data privacy and security?\n",
    "\n",
    "# Write your thoughts here:\n",
    "\"\"\"\n",
    "Your data storage thoughts here\n",
    "\"\"\"\n",
    "\n",
    "# Final Task: Summary\n",
    "# Briefly describe the main issues you found in these Airbnb datasets and how you addressed them\n",
    "# Also, reflect on any challenges you faced during the data preparation process\n",
    "\n",
    "# Write your summary here:\n",
    "\"\"\"\n",
    "Your summary here\n",
    "\"\"\"\n",
    "\n",
    "print(\"Data preparation and cleaning workshop complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
